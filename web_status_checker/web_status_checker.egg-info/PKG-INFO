Metadata-Version: 2.4
Name: web-status-checker
Version: 0.1.0
Summary: Asynchronous website link checker
Author-email: Nils Stenkevics <nils22007488@gmail.com>
License: MIT
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: httpx
Requires-Dist: beautifulsoup4
Requires-Dist: dataclasses-json
Requires-Dist: tqdm
Requires-Dist: jinja2
Requires-Dist: aiohttp
Requires-Dist: httpx[http2]
Requires-Dist: lxml
Requires-Dist: html5lib
Requires-Dist: mypy

# 🌐 Web Status Checker using WebCrawler

This project checks the HTTP status codes of all links found on a given webpage.  
It uses a web crawler approach to extract and validate links — ideal for automation engineers, QA testers, SEO audits, and developers.

---

## 🔍 Features

- Crawls a webpage and collects all internal and external links
- Validates each link's HTTP status code
- Uses multithreading to check links concurrently for better performance
- Displays real-time progress using `tqdm`
- Saves results in a user-friendly HTML report
  - Color-coded status indicators
  - Filter links by success, error, or failure
  - One-click CSV export for offline analysis
- Returns appropriate exit codes for CI/CD or scripting
  - 0 if all links are valid
  - 1 if broken links are found (with --fail-on-broken)
- Accepts command-line arguments for easy automation
- Works across macOS, Windows, and Dockerized environments
- (Optional) Integrates with Playwright for test automation

---

## 🧰 Requirements

### Python Dependencies

Python 3.7 or higher.  
Install the required packages with:

```bash
pip install -r requirements.txt
```

Your `requirements.txt` should contain:

```
httpx
beautifulsoup4
tqdm
jinja2
```

### Node.js Dependencies
Install Node.js (v16+ recommended), then install Playwright:

```bash
npm install -D @playwright/test
npx playwright install
```
---

## 🚀 How to Use the Script

### ✅ Option 1: Run in Terminal (macOS / Linux)

```bash
cd /path/to/WebStatusChecker
python3 webcrawler.py --url https://testpages.herokuapp.com/ --follow
```

### ✅ Option 2: Run in Windows Command Prompt

```cmd
cd path\to\WebStatusChecker
python webcrawler.py --url https://testpages.herokuapp.com/ --follow
```

### ✅ Option 3: Run from PyCharm or another IDE

1.	Open the folder in PyCharm
2. (Optional) Create and activate a virtual environment
3. Run webcrawler.py via the built-in terminal or Run menu
If no arguments are provided, it will prompt you for:

	•	A starting URL

	•	Whether to follow internal links (yes / no)

    •	Whether to fail if broken links are found (yes / no)

If you're using Miniconda inside PyCharm, make sure:
- Your project interpreter is set to the correct Conda environment
- The terminal is opened within that environment to use Python commands

### ✅ Option 4: Run as a Playwright Test
This project includes a Playwright test that runs the Python script and captures its output.
To execute it:
```bash
npx playwright test
```

This **test** is located at: `tests/webcrawler.spec.ts`

Ensure python3 points to the correct environment or adjust to python based on your setup.

#### 📝 Results are saved as html file in test-results folder

---

## ⚙️ CLI Arguments

You can pass arguments directly to skip prompts, useful for automated tests or scripting:

| Argument         | Description                                           | Example                      |
|------------------|-------------------------------------------------------|------------------------------|
| `--url`          | Starting URL to crawl (must include http/https)      | `--url https://linkedin.com` |
| `--follow`       | Follow internal links found during crawling           | `--follow`                   |
| `--max-depth` | Maximum crawl depth for internal links (only used if --follow is set)           | `--max-depth 2`  |
| `--fail-on-broken` | Exit with code 1 if any link fails (for CI pipelines)           | `--fail-on-broken` |


### 🔧 Example usage:
```bash
python3 webcrawler.py --url https://testpages.herokuapp.com/ --follow --max-depth 2 --fail-on-broken
```
> 💡 **Note:**
> - If `--follow` is **not** set, the `--max-depth` argument is **ignored**.
> - In interactive mode, you will only be prompted for crawl depth **if** you choose to follow internal links.

✅ **Tip:** Use `echo $?` (macOS/Linux) or `echo %ERRORLEVEL%` (Windows) after running the script to check the exit code.

* If `--url` is provided, the script **won’t prompt** you for interactive input. Use `--follow` to enable internal crawling.
* If `--fail-on-broken` is set, the script will **return exit code 1** when broken or failed links are found — useful for CI/CD and monitoring workflows.
---


## 🧪 Static Typing & Code Quality

This project uses [mypy](https://mypy-lang.org/) for static type checking.  
It helps detect potential bugs early, enforces better type annotations, and improves long-term maintainability.

### 📋 Running mypy

Install `mypy` if you haven’t already:

```bash
pip install mypy
```
To run the type checker:
```bash
mypy --explicit-package-bases .
```

### Optional: Custom PEP8 Style Rules

This project uses a `setup.cfg` file to define custom code style rules for `pycodestyle`.

To run it:

```bash
pip install pycodestyle
pycodestyle .
```
---

## 📦 Optional: Run in Docker

### Create a Dockerfile

```Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY webcrawler.py .
CMD ["python", "webcrawler.py"]
```

### Build & Run

```bash
docker build -t link-checker .
docker run -it link-checker
```

---

## 🖱️ Optional: Run by Double-Click

### macOS (.command file)

1. Double-click a file called `run_web_status_checker_mac.command`

### Windows (.bat file)

1. Double-click a file called `run_web_status_checker_windows.command`


## 📁 Project Structure

```
WebStatusChecker/
│
├── webcrawler.py                        # Main script
├── requirements.txt                    # Python dependencies
├── tests/
│   └── webcrawler.spec.ts              # Playwright test runner
├── Dockerfile                          # For Dockerized usage (optional)
├── run_web_status_checker_mac.command  # macOS launcher (optional)
├── run_web_status_checker_windows.bat  # Windows launcher (optional)
└── README.md                           # Documentation
```

---

## 🧪 Automation Engineering Tips

- Schedule runs via `cron` (Unix) or Task Scheduler (Windows)
- Add CSV/JSON export for link status results
- Modify to accept multiple URLs as input
- Integrate into CI/CD for automated uptime or SEO checks

---

## 📜 License

MIT — feel free to use, modify, and distribute responsibly.

---

## 👨‍🔧 Author

Created by Nils Stenkēvičs 
Automation-ready and lightweight by design.
